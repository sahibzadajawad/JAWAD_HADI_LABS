{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "from timeseires.utils.to_split import to_split\n",
    "from timeseires.utils.multivariate_multi_step import multivariate_multi_step\n",
    "from timeseires.utils.multivariate_single_step import multivariate_single_step\n",
    "from timeseires.utils.univariate_multi_step import univariate_multi_step\n",
    "from timeseires.utils.univariate_single_step import univariate_single_step\n",
    "from timeseires.utils.CosineAnnealingLRS import CosineAnnealingLRS\n",
    "from timeseires.callbacks.EpochCheckpoint import EpochCheckpoint\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from timeseires.callbacks.TrainingMonitor import TrainingMonitor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D,TimeDistributed\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten,MaxPooling1D,Concatenate,AveragePooling1D, GlobalMaxPooling1D, Input\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "import pandas as pd\n",
    "import time, pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Reshape, Lambda\n",
    "from tensorflow.keras.layers import Layer, Flatten, LeakyReLU, concatenate, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import glob\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lookback = 24\n",
    "model = None\n",
    "start_epoch = 0\n",
    "time_steps=24\n",
    "num_features=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm():\n",
    "    input_data = Input(shape=(time_steps, num_features))\n",
    "    lstm_layer1 = LSTM(8, return_sequences=True)(input_data)\n",
    "    lstm_layer2 = LSTM(20)(lstm_layer1)\n",
    "    x = Flatten()(lstm_layer2)\n",
    "    output_data = Dense(1)(x)\n",
    "    model = Model(input_data, output_data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 24, 21)]          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 24, 8)             960       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                2320      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,301\n",
      "Trainable params: 3,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = create_lstm()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'InvocationException'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\pydot\\core.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1755\u001b[0m                 \u001b[0marguments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1756\u001b[1;33m                 \u001b[0mworking_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1757\u001b[0m             )\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\pydot\\core.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mstdout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m     )\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    799\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    801\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1206\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m   1208\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mcheck_graphviz\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\pydot\\core.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1761\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\"{prog}\" not found in path.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1762\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1763\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12332\\2475081667.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    434\u001b[0m         )\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         message = (\n\u001b[0;32m    438\u001b[0m             \u001b[1;34m\"You must install pydot (`pip install pydot`) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mcheck_graphviz\u001b[1;34m()\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvocationException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'InvocationException'"
     ]
    }
   ],
   "source": [
    "tensorflow.keras.utils.plot_model(model1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\\\E1-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "OUTPUT_PATH = r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 10\\check points'\n",
    "FIG_PATH = os.path.sep.join([OUTPUT_PATH,\"\\history.png\"])\n",
    "JSON_PATH = os.path.sep.join([OUTPUT_PATH,\"\\history.json\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the callback to save only the *best* model to disk\n",
    "# based on the validation loss\n",
    "EpochCheckpoint1 = ModelCheckpoint(checkpoints,\n",
    "                             monitor=\"val_loss\",\n",
    "                             save_best_only=True, \n",
    "                             verbose=1)\n",
    "TrainingMonitor1=TrainingMonitor(FIG_PATH, jsonPath=JSON_PATH, startAt=start_epoch)\n",
    "\n",
    "# construct the set of callbacks\n",
    "callbacks = [EpochCheckpoint1,TrainingMonitor1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "# if there is no specific model checkpoint supplied, then initialize\n",
    "# the network and compile the model\n",
    "if model is None:\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model =create_lstm()\n",
    "    opt = Adam(1e-3)\n",
    "    model.compile(loss= 'mae', optimizer=opt, metrics=[\"mae\", \"mape\"])\n",
    "# otherwise, load the checkpoint from disk\n",
    "else:\n",
    "    print(\"[INFO] loading {}...\".format(model))\n",
    "    model = load_model(model)\n",
    "\n",
    "    # update the learning rate\n",
    "    print(\"[INFO] old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
    "    K.set_value(model.optimizer.lr, 1e-4)\n",
    "    print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84907, 21), (24259, 21), (12130, 21))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path_dataset =r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\AEP_hourly'\n",
    "path_tr = os.path.join(path_dataset, 'AEP_train.csv')\n",
    "df_tr = pd.read_csv(path_tr)\n",
    "train_set = df_tr.iloc[:].values\n",
    "path_v = os.path.join(path_dataset, 'AEP_validation.csv')\n",
    "df_v = pd.read_csv(path_v)\n",
    "validation_set = df_v.iloc[:].values \n",
    "path_te = os.path.join(path_dataset, 'AEP_test.csv')\n",
    "df_te = pd.read_csv(path_te)\n",
    "test_set = df_te.iloc[:].values \n",
    "\n",
    "path_scaler = os.path.join(path_dataset, 'AEP_Scaler.pkl')\n",
    "scaler         = pickle.load(open(path_scaler, 'rb'))\n",
    "\n",
    "train_set.shape, validation_set.shape, test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=24\n",
    "num_features=21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Consumed 0.582646369934082 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train_X , train_y = univariate_multi_step(train_set, time_steps, target_col=0,target_len=1)\n",
    "validation_X, validation_y = univariate_multi_step(validation_set, time_steps, target_col=0,target_len=1)\n",
    "test_X, test_y = univariate_multi_step(test_set, time_steps, target_col=0,target_len=1)\n",
    "print('Time Consumed', time.time()-start, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0359 - mae: 0.0359 - mape: 176.9099\n",
      "Epoch 1: val_loss improved from inf to 0.01558, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0001-loss0.02.h5\n",
      "2653/2653 [==============================] - 66s 22ms/step - loss: 0.0359 - mae: 0.0359 - mape: 176.8732 - val_loss: 0.0156 - val_mae: 0.0156 - val_mape: 7.1791\n",
      "Epoch 2/12\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0135 - mape: 203.6569\n",
      "Epoch 2: val_loss improved from 0.01558 to 0.01382, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0002-loss0.01.h5\n",
      "2653/2653 [==============================] - 58s 22ms/step - loss: 0.0135 - mae: 0.0135 - mape: 203.6144 - val_loss: 0.0138 - val_mae: 0.0138 - val_mape: 6.2203\n",
      "Epoch 3/12\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0108 - mae: 0.0108 - mape: 185.7316\n",
      "Epoch 3: val_loss improved from 0.01382 to 0.01012, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0003-loss0.01.h5\n",
      "2653/2653 [==============================] - 59s 22ms/step - loss: 0.0108 - mae: 0.0108 - mape: 185.7316 - val_loss: 0.0101 - val_mae: 0.0101 - val_mape: 4.8621\n",
      "Epoch 4/12\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0100 - mape: 146.5179\n",
      "Epoch 4: val_loss improved from 0.01012 to 0.00924, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0004-loss0.01.h5\n",
      "2653/2653 [==============================] - 59s 22ms/step - loss: 0.0100 - mae: 0.0100 - mape: 146.4874 - val_loss: 0.0092 - val_mae: 0.0092 - val_mape: 3.9504\n",
      "Epoch 5/12\n",
      "2651/2653 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0095 - mape: 301.8921\n",
      "Epoch 5: val_loss improved from 0.00924 to 0.00922, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0005-loss0.01.h5\n",
      "2653/2653 [==============================] - 60s 23ms/step - loss: 0.0095 - mae: 0.0095 - mape: 301.7156 - val_loss: 0.0092 - val_mae: 0.0092 - val_mape: 4.5145\n",
      "Epoch 6/12\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0091 - mape: 301.8779\n",
      "Epoch 6: val_loss improved from 0.00922 to 0.00853, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0006-loss0.01.h5\n",
      "2653/2653 [==============================] - 61s 23ms/step - loss: 0.0091 - mae: 0.0091 - mape: 301.8145 - val_loss: 0.0085 - val_mae: 0.0085 - val_mape: 4.0838\n",
      "Epoch 7/12\n",
      "2651/2653 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0088 - mape: 397.3087\n",
      "Epoch 7: val_loss improved from 0.00853 to 0.00828, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0007-loss0.01.h5\n",
      "2653/2653 [==============================] - 59s 22ms/step - loss: 0.0088 - mae: 0.0088 - mape: 397.0760 - val_loss: 0.0083 - val_mae: 0.0083 - val_mape: 3.4723\n",
      "Epoch 8/12\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0086 - mape: 209.3145\n",
      "Epoch 8: val_loss did not improve from 0.00828\n",
      "2653/2653 [==============================] - 59s 22ms/step - loss: 0.0086 - mae: 0.0086 - mape: 209.2704 - val_loss: 0.0085 - val_mae: 0.0085 - val_mape: 3.9044\n",
      "Epoch 9/12\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0084 - mae: 0.0084 - mape: 181.8978\n",
      "Epoch 9: val_loss improved from 0.00828 to 0.00809, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0009-loss0.01.h5\n",
      "2653/2653 [==============================] - 64s 24ms/step - loss: 0.0084 - mae: 0.0084 - mape: 181.8978 - val_loss: 0.0081 - val_mae: 0.0081 - val_mape: 3.7069\n",
      "Epoch 10/12\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0081 - mape: 197.5775\n",
      "Epoch 10: val_loss improved from 0.00809 to 0.00749, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0010-loss0.01.h5\n",
      "2653/2653 [==============================] - 64s 24ms/step - loss: 0.0081 - mae: 0.0081 - mape: 197.5361 - val_loss: 0.0075 - val_mae: 0.0075 - val_mape: 3.3071\n",
      "Epoch 11/12\n",
      "2651/2653 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0078 - mape: 131.9930\n",
      "Epoch 11: val_loss did not improve from 0.00749\n",
      "2653/2653 [==============================] - 61s 23ms/step - loss: 0.0078 - mae: 0.0078 - mape: 131.9170 - val_loss: 0.0086 - val_mae: 0.0086 - val_mape: 3.9386\n",
      "Epoch 12/12\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0077 - mae: 0.0077 - mape: 48.7445\n",
      "Epoch 12: val_loss improved from 0.00749 to 0.00747, saving model to C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\checkpoints\\E1-cp-0012-loss0.01.h5\n",
      "2653/2653 [==============================] - 62s 23ms/step - loss: 0.0077 - mae: 0.0077 - mape: 48.7445 - val_loss: 0.0075 - val_mae: 0.0075 - val_mape: 3.2432\n"
     ]
    }
   ],
   "source": [
    "epochs = 12\n",
    "verbose = 1 #0\n",
    "batch_size = 32\n",
    "History = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        batch_size=batch_size,   \n",
    "                        epochs = epochs, \n",
    "                        validation_data = (validation_X,validation_y),\n",
    "                        callbacks=callbacks,verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 10\\check points\\E1-cp-0033-loss0.01.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12332\\280861064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 10\\check points\\E1-cp-0033-loss0.01.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred_scaled\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_pred\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test_unscaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda\\envs\\jawadhadi\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         raise IOError(\n\u001b[1;32m--> 227\u001b[1;33m                             \u001b[1;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m                         )\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 10\\check points\\E1-cp-0033-loss0.01.h5"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_model(r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 10\\check points\\E1-cp-0033-loss0.01.h5')\n",
    "\n",
    "y_pred_scaled   = model.predict(test_X)\n",
    "y_pred          = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "# Mean Absolute Error (MAE)\n",
    "MAE = np.mean(abs(y_pred - y_test_unscaled)) \n",
    "print('Mean Absolute Error (MAE): ' + str(np.round(MAE, 2)))\n",
    "\n",
    "# Median Absolute Error (MedAE)\n",
    "MEDAE = np.median(abs(y_pred - y_test_unscaled))\n",
    "print('Median Absolute Error (MedAE): ' + str(np.round(MEDAE, 2)))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "MSE = np.square(np.subtract(y_pred, y_test_unscaled)).mean()\n",
    "print('Mean Squared Error (MSE): ' + str(np.round(MSE, 2)))\n",
    "\n",
    "# Root Mean Squarred Error (RMSE) \n",
    "RMSE = np.sqrt(np.mean(np.square(y_pred - y_test_unscaled)))\n",
    "print('Root Mean Squared Error (RMSE): ' + str(np.round(RMSE, 2)))\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Mean Absolute Percentage Error (MAPE): ' + str(np.round(MAPE, 2)) + ' %')\n",
    "\n",
    "# Median Absolute Percentage Error (MDAPE)\n",
    "MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Median Absolute Percentage Error (MDAPE): ' + str(np.round(MDAPE, 2)) + ' %')\n",
    "\n",
    "print('\\n\\ny_test_unscaled.shape= ',y_test_unscaled.shape)\n",
    "print('y_pred.shape= ',y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = r'C:\\Users\\Administrator\\Downloads\\ML Lab\\checkpoint\\ML Lab\\lab10\\E2-cp-{epoch:04d}-loss{val_loss:.2f}.h5'\n",
    "model=r'C:\\Users\\Administrator\\Downloads\\ML Lab\\checkpoint\\ML Lab\\lab10\\E1-cp-0033-loss0.01.h5'\n",
    "start_epoch= 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading C:\\Users\\Administrator\\Downloads\\ML Lab\\checkpoint\\ML Lab\\lab10\\E1-cp-0033-loss0.01.h5...\n",
      "[INFO] old learning rate: 0.0010000000474974513\n",
      "[INFO] new learning rate: 9.999999747378752e-05\n"
     ]
    }
   ],
   "source": [
    "# construct the callback to save only the *best* model to disk\n",
    "# based on the validation loss\n",
    "EpochCheckpoint1 = ModelCheckpoint(checkpoints,\n",
    "                             monitor=\"val_loss\",\n",
    "                             save_best_only=True, \n",
    "                             verbose=1)\n",
    "TrainingMonitor1=TrainingMonitor(FIG_PATH, jsonPath=JSON_PATH, startAt=start_epoch)\n",
    "\n",
    "# construct the set of callbacks\n",
    "callbacks = [EpochCheckpoint1,TrainingMonitor1]\n",
    "# if there is no specific model checkpoint supplied, then initialize\n",
    "# the network and compile the model\n",
    "if model is None:\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    model = PC.build(time_steps=24, num_features=21, reg=0.0005)\n",
    "    opt = Adam(1e-3)\n",
    "    model.compile(loss= 'mae', optimizer=opt, metrics=[\"mae\", \"mape\"])\n",
    "# otherwise, load the checkpoint from disk\n",
    "else:\n",
    "    print(\"[INFO] loading {}...\".format(model))\n",
    "    model = load_model(model)\n",
    "\n",
    "    # update the learning rate\n",
    "    print(\"[INFO] old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
    "    K.set_value(model.optimizer.lr, 1e-4)\n",
    "    print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0058 - mae: 0.0058 - mape: 14.8268\n",
      "Epoch 1: val_loss improved from inf to 0.00590, saving model to C:\\Users\\Administrator\\Downloads\\ML Lab\\checkpoint\\ML Lab\\lab10\\E2-cp-0001-loss0.01.h5\n",
      "2653/2653 [==============================] - 58s 21ms/step - loss: 0.0058 - mae: 0.0058 - mape: 14.8268 - val_loss: 0.0059 - val_mae: 0.0059 - val_mape: 2.4532\n",
      "Epoch 2/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0058 - mae: 0.0058 - mape: 30.0224\n",
      "Epoch 2: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 60s 23ms/step - loss: 0.0058 - mae: 0.0058 - mape: 30.0224 - val_loss: 0.0060 - val_mae: 0.0060 - val_mape: 2.4553\n",
      "Epoch 3/10\n",
      "2652/2653 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0058 - mape: 14.1057\n",
      "Epoch 3: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 58s 22ms/step - loss: 0.0058 - mae: 0.0058 - mape: 14.1030 - val_loss: 0.0060 - val_mae: 0.0060 - val_mape: 2.5044\n",
      "Epoch 4/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 8.3475\n",
      "Epoch 4: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 57s 22ms/step - loss: 0.0057 - mae: 0.0057 - mape: 8.3475 - val_loss: 0.0060 - val_mae: 0.0060 - val_mape: 2.4573\n",
      "Epoch 5/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 8.5071\n",
      "Epoch 5: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 57s 21ms/step - loss: 0.0057 - mae: 0.0057 - mape: 8.5071 - val_loss: 0.0060 - val_mae: 0.0060 - val_mape: 2.4812\n",
      "Epoch 6/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 36.9960\n",
      "Epoch 6: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 58s 22ms/step - loss: 0.0057 - mae: 0.0057 - mape: 36.9960 - val_loss: 0.0060 - val_mae: 0.0060 - val_mape: 2.4587\n",
      "Epoch 7/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 17.4405\n",
      "Epoch 7: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 59s 22ms/step - loss: 0.0057 - mae: 0.0057 - mape: 17.4405 - val_loss: 0.0061 - val_mae: 0.0061 - val_mape: 2.5434\n",
      "Epoch 8/10\n",
      "2651/2653 [============================>.] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 28.4302\n",
      "Epoch 8: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 60s 22ms/step - loss: 0.0057 - mae: 0.0057 - mape: 28.4143 - val_loss: 0.0060 - val_mae: 0.0060 - val_mape: 2.4735\n",
      "Epoch 9/10\n",
      "2651/2653 [============================>.] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 7.0884\n",
      "Epoch 9: val_loss improved from 0.00590 to 0.00590, saving model to C:\\Users\\Administrator\\Downloads\\ML Lab\\checkpoint\\ML Lab\\lab10\\E2-cp-0009-loss0.01.h5\n",
      "2653/2653 [==============================] - 60s 23ms/step - loss: 0.0057 - mae: 0.0057 - mape: 7.0859 - val_loss: 0.0059 - val_mae: 0.0059 - val_mape: 2.4322\n",
      "Epoch 10/10\n",
      "2653/2653 [==============================] - ETA: 0s - loss: 0.0057 - mae: 0.0057 - mape: 8.8564\n",
      "Epoch 10: val_loss did not improve from 0.00590\n",
      "2653/2653 [==============================] - 59s 22ms/step - loss: 0.0057 - mae: 0.0057 - mape: 8.8564 - val_loss: 0.0059 - val_mae: 0.0059 - val_mape: 2.4287\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "verbose = 1 #0\n",
    "batch_size = 32\n",
    "History = model.fit(train_X,\n",
    "                        train_y,\n",
    "                        batch_size=batch_size,   \n",
    "                        epochs = epochs, \n",
    "                        validation_data = (validation_X,validation_y),\n",
    "                        callbacks=callbacks,\n",
    "                        verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 1s 2ms/step\n",
      "Mean Absolute Error (MAE): 177.88\n",
      "Median Absolute Error (MedAE): 146.2\n",
      "Mean Squared Error (MSE): 52518.91\n",
      "Root Mean Squared Error (RMSE): 229.17\n",
      "Mean Absolute Percentage Error (MAPE): 1.25 %\n",
      "Median Absolute Percentage Error (MDAPE): 0.99 %\n",
      "\n",
      "\n",
      "y_test_unscaled.shape=  (12105, 1)\n",
      "y_pred.shape=  (12105, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_model(r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 8 checkpoints\\E1-cp-0009-loss0.01.h5')\n",
    "\n",
    "y_pred_scaled   = model.predict(test_X)\n",
    "y_pred          = scaler.inverse_transform(y_pred_scaled)\n",
    "y_test_unscaled = scaler.inverse_transform(test_y)\n",
    "# Mean Absolute Error (MAE)\n",
    "MAE = np.mean(abs(y_pred - y_test_unscaled)) \n",
    "print('Mean Absolute Error (MAE): ' + str(np.round(MAE, 2)))\n",
    "\n",
    "# Median Absolute Error (MedAE)\n",
    "MEDAE = np.median(abs(y_pred - y_test_unscaled))\n",
    "print('Median Absolute Error (MedAE): ' + str(np.round(MEDAE, 2)))\n",
    "\n",
    "# Mean Squared Error (MSE)\n",
    "MSE = np.square(np.subtract(y_pred, y_test_unscaled)).mean()\n",
    "print('Mean Squared Error (MSE): ' + str(np.round(MSE, 2)))\n",
    "\n",
    "# Root Mean Squarred Error (RMSE) \n",
    "RMSE = np.sqrt(np.mean(np.square(y_pred - y_test_unscaled)))\n",
    "print('Root Mean Squared Error (RMSE): ' + str(np.round(RMSE, 2)))\n",
    "\n",
    "# Mean Absolute Percentage Error (MAPE)\n",
    "MAPE = np.mean((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Mean Absolute Percentage Error (MAPE): ' + str(np.round(MAPE, 2)) + ' %')\n",
    "\n",
    "# Median Absolute Percentage Error (MDAPE)\n",
    "MDAPE = np.median((np.abs(np.subtract(y_test_unscaled, y_pred)/ y_test_unscaled))) * 100\n",
    "print('Median Absolute Percentage Error (MDAPE): ' + str(np.round(MDAPE, 2)) + ' %')\n",
    "\n",
    "print('\\n\\ny_test_unscaled.shape= ',y_test_unscaled.shape)\n",
    "print('y_pred.shape= ',y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files: ['history.json', 'history.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = r'C:\\Users\\Hp\\Desktop\\ml labs\\last labs\\lab 10\\check points'\n",
    "print(\"Available files:\", os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
